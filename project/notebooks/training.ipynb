{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7277e4e4-b8a4-4855-963d-e7f0717f47de",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72176fe2-31a3-4fde-8b95-cc29948f5d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed sympy-1.13.1 torch-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a261873-238d-4118-9d7c-fe9923953c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.30.2 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f2095-7054-45ef-8fb4-2a846419d534",
   "metadata": {},
   "source": [
    "## Due to Jupyter constraints and crash issues this notebook represents only a sample of the training process (1 epoch)\n",
    "## In reality, every model is trained for 50 epochs or Early stopping in the terminal separately. \n",
    "## The log files for the 50 epoch trainings are attached as a part of the repository under the folder \"training_logs\"\n",
    "## The models used for predictions, inference and loss calculations are 50 epochs trained ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "477ec9c6-d63e-4119-a3e8-75ffd34f2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import yaml\n",
    "import time\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "014cae79-ca15-48cd-8fa9-6eeabe790ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"../src/dataset/processed/split_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b80ced2-8a2e-4df3-9db4-0f881fa9ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef0b497c-75d3-41de-9f56-6e608d88cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90da6b4e-ae80-4665-a757-c737114e1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        assert len(texts) == len(labels), \"Length of texts and labels must be the same\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoded_text = self.tokenizer.encode_plus(\n",
    "            self.texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=120,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        \n",
    "        return (encoded_text['input_ids'].squeeze(0), encoded_text['attention_mask'].squeeze(0)), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "766df719-0627-44ae-a82a-f2264258ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = data[\"train_texts\"], data[\"train_labels\"]\n",
    "valid_texts, valid_labels = data[\"valid_texts\"], data[\"valid_labels\"]\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer_vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c5a3d81-2821-4967-82bd-be1a4d98e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetLoader(train_texts, train_labels, tokenizer)\n",
    "valid_dataset = DatasetLoader(valid_texts, valid_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "facafc4a-e53b-4771-acad-764dc422cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f3164bc-4d5a-4734-9fca-4b0db04aef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    DEVICE_TYPE = \"mps\"\n",
    "else:\n",
    "    DEVICE_TYPE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "66912be7-5f9a-4a76-a2da-da16456a1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = \"CNN_Model\"\n",
    "lstm_tc_model = \"LSTM_Text_Classifier\"\n",
    "mlp_class_model = \"MLP_Classifier\"\n",
    "lstm_multihead = \"LSTM_Multi_Head_Attention\"\n",
    "rcnn = \"RCNN_Text_Classifier\"\n",
    "bigru = \"BiGRU_Attention_Residual\"\n",
    "yml_file_path = \"../src/configs/hyperparams.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04fbc6c9-b41e-4435-9200-9b9c5b3dd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config_file(file_name,model_name):\n",
    "    try:\n",
    "        with open(file_name, \"r\") as yamlfile:\n",
    "            data = yaml.load(yamlfile, Loader=yaml.FullLoader)\n",
    "            if model_name:\n",
    "                if model_name in data:\n",
    "                    model_parameters = data[model_name]\n",
    "            else:\n",
    "                model_parameters = data\n",
    "            return model_parameters\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        model_parameters = {}\n",
    "        return model_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc0a007c-5025-4733-94f5-4ff477fdc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            @patience (int): How long to wait after last time validation loss improved.\n",
    "            @verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "            @delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss):\n",
    "        \"\"\"\n",
    "        Saves model checkpoints when validation loss decrease.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "79bea433-6c95-44c4-8fc2-7266019f9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, loss_fn, epochs=10, \n",
    "          model_save_path='models/best_model.pth',early_stopping=None,device=DEVICE_TYPE):\n",
    "    set_seed(2023)\n",
    "    best_accuracy = 0\n",
    "    print(\"=========Starting Training==========\")\n",
    "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        t0_epoch = time.time()\n",
    "        total_loss = 0\n",
    "        for batch_X ,batch_labels in train_loader:\n",
    "            input_ids, attention_masks = batch_X\n",
    "            model.zero_grad()\n",
    "            logits = model(input_ids.to(DEVICE_TYPE))\n",
    "            loss = loss_fn(logits, batch_labels.to(device))\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        if val_loader is not None:\n",
    "            \n",
    "            val_loss, val_accuracy = evaluate(model, val_loader, loss_fn, device)\n",
    "            if early_stopping:\n",
    "                early_stopping(val_loss)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "                os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            print(f\"{epoch + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "    print(\"\\n\")\n",
    "    print(\"==========Best Accuracy After training================\",best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac6ef102-0106-41c2-898a-df7d80d550ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, loss_fn, device=DEVICE_TYPE):\n",
    "    model.eval()\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for val_batch_input, val_batch_label in val_loader:\n",
    "            input_ids, attention_masks = val_batch_input\n",
    "            logits = model(input_ids.to(DEVICE_TYPE))\n",
    "            loss = loss_fn(logits, val_batch_label.to(device))\n",
    "            val_loss.append(loss.item())\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            labels = torch.argmax(val_batch_label, dim=1)\n",
    "            accuracy = (preds == labels.to(device)).float().mean() * 100\n",
    "            val_accuracy.append(accuracy.item())\n",
    "\n",
    "        val_loss = torch.tensor(val_loss).mean().item()\n",
    "        val_accuracy = torch.tensor(val_accuracy).mean().item()\n",
    "    \n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d73c03-3d3e-41ee-9ae0-652110271742",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2afe2649-3da2-4f8e-ad6a-7677269df347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_dim=256, \n",
    "                 filter_sizes=[3, 4, 5],\n",
    "                 num_filters=[200, 250, 200],\n",
    "                 num_classes=3,\n",
    "                 dropout=0.5\n",
    "                 ):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embed_dim, out_channels=num_filters[i],\n",
    "                     kernel_size=filter_sizes[i])\n",
    "            for i in range(len(filter_sizes))\n",
    "        ])\n",
    "        self.fc1 = nn.Linear(np.sum(num_filters), 256)     \n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding(x)\n",
    "        x_reshaped = x_embed.permute(0, 2, 1)\n",
    "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
    "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2]) for x_conv in x_conv_list]\n",
    "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list], dim=1)\n",
    "        fc1 = self.dropout(F.relu(self.fc1(x_fc)))\n",
    "        logits = self.fc2(fc1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "725e0f96-e880-4a39-9906-6915e2260c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = read_config_file(yml_file_path, cnn_model)\n",
    "model_params['vocab_size'] = tokenizer_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4c169474-4055-450a-9324-67fc58363e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model(**model_params)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.01, rho=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9e762aff-00f3-45c3-87de-f08c9e68a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3e82735d-9b72-4022-b648-351bbca64e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (embedding): Embedding(30522, 128)\n",
       "  (conv1d_list): ModuleList(\n",
       "    (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (fc1): Linear(in_features=448, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6415441d-72d1-475b-9b8c-51fcef57365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c465300a-3b81-47e4-9905-3b882a398bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Starting Training==========\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 0.540565).  Saving model ...\n",
      "   1    |   0.652857   |  0.540565  |   75.51   |  207.71  \n",
      "\n",
      "\n",
      "==========Best Accuracy After training================ 75.51349639892578\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_loader, valid_loader, loss_fn, epochs=1, model_save_path=f'models/{cnn_model}_epoch_1', early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6cfad-50a7-40ad-99fa-f393296cadbd",
   "metadata": {},
   "source": [
    "### LSTM Text Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "beeb34d8-3262-4708-994f-4ba3ff20f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Text_Classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        \"\"\"\n",
    "        Initialize the LSTMTextClassifier model.\n",
    "\n",
    "        Parameters:\n",
    "        @vocab_size: Size of the vocabulary.\n",
    "        @embedding_dim: Dimension of the input embeddings.\n",
    "        @hidden_dim: Dimension of the hidden state in the LSTM.\n",
    "        @output_dim: Number of classes in the output layer.\n",
    "        @n_layers: Number of layers in the LSTM.\n",
    "        @bidirectional: If True, initializes a bidirectional LSTM.\n",
    "        @dropout: Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(LSTM_Text_Classifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        Params:\n",
    "        @x: input_ids\n",
    "        Returns: The logits for each class.\n",
    "        \"\"\"\n",
    "        text_embeddings = self.embedding(x)\n",
    "        lstm_out, (hidden,cell) = self.lstm(text_embeddings)\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "        hidden = self.dropout(hidden)\n",
    "        logits = self.fc(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "315535c0-71d8-4271-beee-58f6b5ac1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = read_config_file(yml_file_path, lstm_tc_model)\n",
    "model_params['vocab_size'] = tokenizer_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "73191014-da89-46c8-9e2c-89592c220871",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Text_Classifier(**model_params)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.01, rho=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e9c26e54-4164-4959-a708-0ed9880b0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "61649b7f-b5e7-4056-bc72-1d240d77fb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_Text_Classifier(\n",
       "  (embedding): Embedding(30522, 128)\n",
       "  (lstm): LSTM(128, 128, num_layers=6, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "605f274d-dfca-4dd4-8cf1-a7fe4b0a52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2a0abcd1-bffd-4f16-a2cf-485327ac1694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Starting Training==========\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.098479).  Saving model ...\n",
      "   1    |   1.098663   |  1.098479  |   34.19   |  697.25  \n",
      "\n",
      "\n",
      "==========Best Accuracy After training================ 34.18667221069336\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_loader, valid_loader, loss_fn, epochs=1, model_save_path=f'models/{lstm_tc_model}_epoch_1', early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04564092-2f70-44b7-866a-18bed0bfae6d",
   "metadata": {},
   "source": [
    "### MLP Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "59cdc641-3948-4fda-b7cb-59ac9b7818db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, input_dim, hidden_size, num_classes=2, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        @vocab_size: Size of the vocabulary.\n",
    "        @input_dim: Dimension of the input embeddings.\n",
    "        @hidden_dim: Dimension of the hidden state in the LSTM.\n",
    "        @num_classes: Number of classes in the output layer.\n",
    "        @dropout: Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(MLP_Classifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, input_dim)\n",
    "        self.fc1 = nn.Linear(input_dim * 120, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, hidden_size // 4)\n",
    "        self.fc4 = nn.Linear(hidden_size // 4, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x)\n",
    "        x = embeddings.view(embeddings.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "08b93ebd-d5e2-4d42-b398-fe4c3541d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = read_config_file(yml_file_path, mlp_class_model)\n",
    "model_params['vocab_size'] = tokenizer_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "43cff56c-6711-4f8e-a445-fc78a8225148",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_Classifier(**model_params)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.01, rho=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "680fb2e1-9570-45b2-b78d-7ee8b6d5be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "95868b43-3fa5-4447-8fc4-8edb2aeadcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP_Classifier(\n",
       "  (embedding): Embedding(30522, 128)\n",
       "  (fc1): Linear(in_features=15360, out_features=2048, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc4): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4b77284d-6d99-414d-b20b-e31ffd52b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c054f67c-bb18-4bd9-bc58-b7d25baa8303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Starting Training==========\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 0.834795).  Saving model ...\n",
      "   1    |   0.897569   |  0.834795  |   59.79   |  174.80  \n",
      "\n",
      "\n",
      "==========Best Accuracy After training================ 59.79225158691406\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_loader, valid_loader, loss_fn, epochs=1, model_save_path=f'models/{mlp_class_model}_epoch_1', early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa398c9-93fa-4f1e-b1bc-cf4f315d43a3",
   "metadata": {},
   "source": [
    "### LSTM Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2e434ea4-de1d-4f9e-98dd-42ca2d4fe6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, vocab_size, input_dim, hidden_dim, output_dim, num_layers, bidirectional , dropout,\n",
    "                num_heads):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        @vocab_size: Size of the vocabulary.\n",
    "        @embedding_dim: Dimension of the input embeddings.\n",
    "        @hidden_dim: Dimension of the hidden state in the LSTM.\n",
    "        @output_dim: Number of classes in the output layer.\n",
    "        @n_layers: Number of layers in the LSTM.\n",
    "        @bidirectional: If True, initializes a bidirectional LSTM.\n",
    "        @dropout: Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(LSTM_Multi_Head_Attention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, input_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.bidirectional = bidirectional\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, bidirectional=self.bidirectional, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Attention Layer\n",
    "        if self.bidirectional:\n",
    "            self.head_dim = hidden_dim * 2 // num_heads\n",
    "        else:\n",
    "            self.head_dim = hidden_dim // num_heads\n",
    "        assert self.hidden_dim % num_heads == 0, \"hidden_dim must be divisible by the number of heads\"\n",
    "        if self.bidirectional:\n",
    "            self.query_layers = nn.ModuleList([nn.Linear(hidden_dim * 2, self.head_dim) for _ in range(self.num_heads)])\n",
    "            self.key_layers = nn.ModuleList([nn.Linear(hidden_dim * 2, self.head_dim) for _ in range(self.num_heads)])\n",
    "            self.value_layers = nn.ModuleList([nn.Linear(hidden_dim * 2, self.head_dim) for _ in range(self.num_heads)])\n",
    "        elif not self.bidirectional:\n",
    "            self.query_layers = nn.ModuleList([nn.Linear(hidden_dim, self.head_dim) for _ in range(self.num_heads)])\n",
    "            self.key_layers = nn.ModuleList([nn.Linear(hidden_dim, self.head_dim) for _ in range(self.num_heads)])\n",
    "            self.value_layers = nn.ModuleList([nn.Linear(hidden_dim, self.head_dim) for _ in range(self.num_heads)])\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.last_attention_weights = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def attention_net(self, lstm_outputs):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention mechanism\n",
    "        \"\"\"\n",
    "        attention_outputs = []\n",
    "        attention_scores = []\n",
    "        for i in range(self.num_heads):\n",
    "            Q = self.query_layers[i](lstm_outputs)\n",
    "            Q = self.dropout(Q)\n",
    "            K = self.key_layers[i](lstm_outputs)\n",
    "            K = self.dropout(K)\n",
    "            V = self.value_layers[i](lstm_outputs)\n",
    "            V = self.dropout(V)\n",
    "            scores = torch.bmm(Q, K.transpose(1, 2)) / (self.head_dim ** 0.5)\n",
    "            scores = F.softmax(scores, dim=-1)\n",
    "            output = torch.bmm(scores, V)\n",
    "            attention_scores.append(scores)\n",
    "            attention_outputs.append(output)\n",
    "        final_output = torch.cat(attention_outputs, dim=-1)\n",
    "        self.last_attention_weights = attention_scores\n",
    "        return final_output, attention_scores\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).requires_grad_().to(DEVICE_TYPE)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).requires_grad_().to(DEVICE_TYPE)\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, (hn, cn) = self.lstm(x, (h0.detach(),c0.detach()))\n",
    "        attention_output, attention_weights = self.attention_net(lstm_out)\n",
    "        final_attention_output = torch.mean(attention_output, dim=1)\n",
    "        out = self.fc(final_attention_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "94b00783-2d0f-4ff0-a55d-0f2ad10fa208",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = read_config_file(yml_file_path, lstm_multihead)\n",
    "model_params['vocab_size'] = tokenizer_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f3f4e376-1165-47d3-9a6b-5cc557c1fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Multi_Head_Attention(**model_params)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.01, rho=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bbd3576e-9b9e-441b-80a4-ce864876568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "900d77b3-eaf8-4037-8e50-f71f3ca7c035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_Multi_Head_Attention(\n",
       "  (embedding): Embedding(30522, 128)\n",
       "  (lstm): LSTM(128, 128, num_layers=6, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (query_layers): ModuleList(\n",
       "    (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
       "  )\n",
       "  (key_layers): ModuleList(\n",
       "    (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
       "  )\n",
       "  (value_layers): ModuleList(\n",
       "    (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4880710e-6be0-4e93-9604-9c7d289c6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cf20bc4d-9d4e-408e-a22d-69cf75ea246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Starting Training==========\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.098421).  Saving model ...\n",
      "   1    |   1.098405   |  1.098421  |   34.19   |  1038.37 \n",
      "\n",
      "\n",
      "==========Best Accuracy After training================ 34.18667221069336\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_loader, valid_loader, loss_fn, epochs=1, model_save_path=f'models/{lstm_multihead}_epoch_1', early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a2157-b20c-48c1-8185-e1d162b9431c",
   "metadata": {},
   "source": [
    "### RCNN Text Classifier (Combine LSTM and CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8204db22-4205-4b8c-b5ae-215cc840995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN_Text_Classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout):\n",
    "        \"\"\"\n",
    "        RCNN model combining LSTM and CNN.\n",
    "\n",
    "        Params:\n",
    "        @vocab_size: Size of vocabulary.\n",
    "        @embedding_dim: Dimension of input embeddings.\n",
    "        @hidden_dim: Hidden state size for LSTM.\n",
    "        @output_dim: Number of output classes.\n",
    "        @dropout: Dropout rate.\n",
    "        \"\"\"\n",
    "        super(RCNN_Text_Classifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.conv = nn.Conv1d(in_channels=embedding_dim + 2 * hidden_dim, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(128, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x)  # [B, T, D]\n",
    "        lstm_out, _ = self.lstm(embeddings)  # [B, T, 2H]\n",
    "        combined = torch.cat([embeddings, lstm_out], dim=2)  # [B, T, D+2H]\n",
    "        combined = combined.permute(0, 2, 1)  # [B, D+2H, T]\n",
    "        conv_out = F.relu(self.conv(combined))  # [B, 128, T]\n",
    "        pooled = F.max_pool1d(conv_out, kernel_size=conv_out.shape[2]).squeeze(2)  # [B, 128]\n",
    "        dropped = self.dropout(pooled)\n",
    "        logits = self.fc(dropped)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b9e25e17-4897-44d5-95f2-7e9d0ba5f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_model_params = read_config_file(yml_file_path, rcnn)\n",
    "rcnn_model_params['vocab_size'] = tokenizer_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a746ac72-46f3-4f4b-a7e4-4cf2949929a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_model = RCNN_Text_Classifier(**rcnn_model_params)\n",
    "rcnn_optimizer = optim.Adadelta(rcnn_model.parameters(), lr=0.01, rho=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0eb49235-1bb2-4890-b886-235b2f979109",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "072ca6e2-e034-4cc7-b0fc-535603938cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RCNN_Text_Classifier(\n",
       "  (embedding): Embedding(30522, 128)\n",
       "  (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
       "  (conv): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcnn_model.to(DEVICE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6a32deee-801d-4095-bfbe-862aa46d8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_early_stopping = EarlyStopping(patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d6d28aad-b294-4d97-a585-90b916bc9ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Starting Training==========\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 0.569093).  Saving model ...\n",
      "   1    |   0.692761   |  0.569093  |   74.90   |  244.58  \n",
      "\n",
      "\n",
      "==========Best Accuracy After training================ 74.90386962890625\n"
     ]
    }
   ],
   "source": [
    "train(rcnn_model, rcnn_optimizer, train_loader, valid_loader, loss_fn, epochs=1, model_save_path=f'models/{rcnn}_epoch_1', early_stopping=rcnn_early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee703e-a9d0-42fa-988e-c50c9474073d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
